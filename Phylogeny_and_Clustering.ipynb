{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "NL2DS - Winter 2023\n",
        "\n",
        "Assignment 5 -- Language Phylogeny and Clustering"
      ],
      "metadata": {
        "id": "twQqXe7yn1aD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lBgAZhME8pBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: **[YOUR NAME HERE]**\n",
        "\n",
        "Student ID: **[YOUR STUDENT ID HERE]**"
      ],
      "metadata": {
        "id": "7E8heQjIoHqL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNeTggCnm61l"
      },
      "source": [
        "In this assignment, we will look at some cross-linguistic word form data and use some of the tools we saw in class to build family trees of languages based on the sound forms of words---otherwise known as \"optimal phylogenies.\" \n",
        "\n",
        "We will use data from the following recent paper.\n",
        "\n",
        "\n",
        "[Dellert, Johannes, Daneyko, T., Muench, A., Ladygina, A., Buch, A., Clarius, N., Grigorjew, I., Balabel, M., Boga, H. I., Baysarova, Z., Muehlenbernd, R., Wahle, J., and Jaeger, G. (2020). Northeuralex: A wide-coverage lexical database of northern eurasia. Language Resources & Evaluation, 54(273â€“301).](https://drive.google.com/file/d/1ptoMNctdJs99wPWfBUGbw4_X60NtKl9B/view?usp=sharing)\n",
        "\n",
        "This data  can be found [here](http://northeuralex.org/) as well.\n",
        "\n",
        "Copy the data to your drive folder from: [here](https://drive.google.com/file/d/1Mfa8XayBFJb0fY8wfinODw90yuRal8AD/view?usp=sharing), [here](https://drive.google.com/file/d/1AQqkscWKlq3quw-BWjB8xqSQzm7-uDtt/view?usp=sharing), and [here](https://drive.google.com/file/d/1R7ZLEzDW9QKUen3BjItPsySaUPCpu7xk/view?usp=sharing)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1**"
      ],
      "metadata": {
        "id": "vOj99IzPpfVz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B3OQyn4zZRo"
      },
      "source": [
        "***Question 1:*** What is the Northeuralex dataset? Give a brief overview. What kind of data is it? What is its purpose? How was it constructed? No need to go into all of the particulars (such as fields of the files), just give an overview of no more than one paragraph that gives the gist for someone unfamiliar with the dataset.\n",
        "\n",
        "**A1: put your answer here (please keep it brief, 3-5 sentences)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's read in the wordforms in this dataset."
      ],
      "metadata": {
        "id": "_lulwM8kooi6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfVlyC-buz1i"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "import pandas as pd\n",
        "wordforms=pd.read_csv(\"/content/drive/My Drive/northeuralex.csv\")\n",
        "display(wordforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jBeO3Civbry"
      },
      "source": [
        "***Question 2:*** Describe the meaning of the `Langauge_ID`, `Concept_ID`, `rawIPA` and `IPA` columns of the data.\n",
        "\n",
        "**A2: put your answer here (please keep it brief, no more than 1 sentence per column)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's read in some metadata about the languages."
      ],
      "metadata": {
        "id": "RNSrreIKo6r5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov3JtI5lvc0g"
      },
      "source": [
        "languages=pd.read_csv(\"/content/drive/My Drive/northeuralex-languages.csv\")\n",
        "display(languages)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhxJBBlbvtzx"
      },
      "source": [
        "***Question 3:*** Describe the meaning of the `family`, `iso_code`, and `subfamily` columns of the data.\n",
        "\n",
        "**A3: put your answer here (please keep it brief, no more than 1 sentence per column)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's read in some further data about the concepts."
      ],
      "metadata": {
        "id": "qEroeQmKpJ1F"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um70edh5vyiB"
      },
      "source": [
        "concepts=pd.read_csv(\"/content/drive/My Drive/northeuralex-concepts.csv\")\n",
        "display(concepts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpwbBHZiv2dK"
      },
      "source": [
        "***Question 4:*** Describe the meaning of the `id_nelex`, `gloss_en`, and `position_in_ranking` columns of the data.\n",
        "\n",
        "**A4: put your answer here (please keep it brief, no more than 1 sentence per column)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 2**"
      ],
      "metadata": {
        "id": "9Hz1qeNbp5h0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It will be useful to merge all of the meta-information into the main wordforms dataframe."
      ],
      "metadata": {
        "id": "J4Njm0Taptwe"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fztpd5H4P733"
      },
      "source": [
        "# Problem 1a: rename the appropriate columns in the languages and concepts dataframes to make this merge possible.\n",
        "#your code here\n",
        "\n",
        "# Problem 1b: Use the merge function to merge the three dataframes into one.\n",
        "#your code here\n",
        "\n",
        "display(wordforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWS-b5Oaj7IA"
      },
      "source": [
        "In this problem set, we will make use of the `lingpy` package of tools for historical linguistics. You can find more information on this [here](ttps://lingpy.org/index.html). We'll start by installing the package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_X1Ls_hkDlw"
      },
      "source": [
        "!pip install lingpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6lw4vrf4rSF"
      },
      "source": [
        "In order to make our computations below more manageable, we will focus on the Indo-european languages which you can read more about [here](https://en.wikipedia.org/wiki/Indo-European_languages). We will also focus just on the top 20 concepts as determined by their rank."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n6vi-YA5iwL"
      },
      "source": [
        "#Problem 2a: Filter out the non-Indo-European languages from the dataframes\n",
        "#your code here\n",
        "\n",
        "#Problem 2b: Filter the concepts to include those less than or equal to rank 20 in the dataframe.\n",
        "# your code here\n",
        "\n",
        "display(wordforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 3**"
      ],
      "metadata": {
        "id": "-_A1rzbkqY5n"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb68zqmAkc7n"
      },
      "source": [
        "Our goal is to use agglomerative clustering to try to reconstruct the tree for the indoeuropean languages. You can find a reference tree (for families) [here](https://en.wikipedia.org/wiki/Indo-European_languages#/media/File:IndoEuropeanLanguageFamilyRelationsChart.jpg).\n",
        "\n",
        "In order to do this, we will need to construct a  matrix of similarities between the languages, called a confusion matrix.\n",
        "\n",
        "We will compute the (normalized) levenshtein distance between the strings for each concept for each pair of languages. For instance, we will compute the normalized levenshtein distance between the words for Wasser::N (water in English) for German and English and then similarily for all 19 other concepts. If there are multiple words for the same concept, take the average across all pair possibilities. We will then average these values (i.e., average across all concepts) to find the similarity between German and English. We will do this for all pairs of languages to create a list of lists representing the confusion matrix.\n",
        "\n",
        "Note that running your code will take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CohUtqFkiJV"
      },
      "source": [
        "import lingpy as lp\n",
        "import numpy as np\n",
        "\n",
        "#Problem 3: fill the confusion matrix  using the \n",
        "#lp.align.pairwise.edit_dist function from lingpy, on \n",
        "#the \"IPA\" fields for each language.\n",
        "\n",
        "#initialize confusion matrix\n",
        "language_list = None # Initialise list of languages in the current modified wordforms dataset\n",
        "confusion = [[0 for j in range(len(language_list))] for i in range(len(language_list))]\n",
        "\n",
        "for language1 in ...\n",
        "  for language2 in ...\n",
        "    ...\n",
        "    for concept in ...\n",
        "      ...\n",
        "    confusion[language1][language2]=..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clear the output of the above cell (by clicking on the cross at top left of the output part) so that it doesn't clutter the pdf."
      ],
      "metadata": {
        "id": "Drf6fCN4F77y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VEsX9X9kpkZ"
      },
      "source": [
        "Now that we have computed a matrix of similarities, we can use clustering algorithms to try to build phylogenetic trees representing the languages historical relationships. First, let's use the `lp.algorithm.clustering.flat_cluster` function from `lingpy` to derive a flat clustering of languages. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuOZmR85kqAf"
      },
      "source": [
        "lp.algorithm.clustering.flat_cluster('upgma', 0.6, confusion, language_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "780yD_sq9Xx_"
      },
      "source": [
        "***Question 5:*** Do you recognize any of the clusters of languages? Are there any noteworthy errors in this clustering?\n",
        "\n",
        "**A5: put your answer here (please keep it brief, no more than 4-5 sentences.)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 4**"
      ],
      "metadata": {
        "id": "wRsc8ZLlrHag"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxx3zF-l-DyJ"
      },
      "source": [
        "Now we will build our own dendrogram using the clustering algorithms available in [`scipy`](https://docs.scipy.org/doc/scipy/reference/cluster.hierarchy.html). You can read in particular about the [`linkage`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html) function and the [`dendrogram`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.dendrogram.html) function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wDYHMB7g2Vw"
      },
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from sklearn.metrics import v_measure_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Problem 4: use the linkage function with the average linkage method to compute the clustering.\n",
        "linked = ...\n",
        "\n",
        "\n",
        "#plot the results using dendrogram\n",
        "def llf(id): return language_list[id]\n",
        "plt.figure(figsize=(12, 8))\n",
        "dendrogram(linked,\n",
        "           p=100,\n",
        "           truncate_mode=\"level\",\n",
        "           orientation='top',\n",
        "           distance_sort='descending',\n",
        "           show_leaf_counts=False,\n",
        "           leaf_label_func=llf)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XKrzEvlAgO5"
      },
      "source": [
        "***Question 6:*** Do you recognize any of the clusters of languages at any of the levels? Are there any noteworthy errors in this clustering?\n",
        "\n",
        "**A6: put your answer here (please keep it brief, no more than 4-5 sentences.)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 5**"
      ],
      "metadata": {
        "id": "WLrjiJQdxQzP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question 7:*** Try three of the other linkage methods and describe how they change the results.\n",
        "\n",
        "**A7: Put your answer here (please keep it brief, no more than 4-5 sentences). Include all the code in separate cells.**\n",
        "\n",
        "\n",
        "***Question 8:*** Try increasing the number of concepts we use to compute our confusion matrix to be higher than 20. Does it change the results?\n",
        "\n",
        "**A8: Put your answer here (please keep it brief, no more than 3-4 sentences). Include all the code in separate cells.**"
      ],
      "metadata": {
        "id": "bYY9y-usxGp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To Submit\n",
        "To submit, name this notebook `YOUR_STUDENT_ID_Assignment_5.ipynb`, then convert this `.ipynb` file to a `.pdf` (e.g., using the following instructions) and upload the PDF to the Gradescope assignment \"Assignment 5 -- Language Phylogeny and Clustering\".\n",
        "\n",
        "(Note: `Print > Save as PDF` **will not work** because it will not display your figures correctly.)\n",
        "\n",
        "You can convert the notebook to a PDF using the following instructions."
      ],
      "metadata": {
        "id": "FL7VRHX3CE6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting this notebook to a PDF"
      ],
      "metadata": {
        "id": "A_PZj4fgA70w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Make sure you have renamed the notebook, e.g. `000000000_Assignment_5.ipynb` where `000000000` is your student ID.\n",
        "2. Make sure to save the notebook (`ctrl/cmd + s`)."
      ],
      "metadata": {
        "id": "CEUQt-EbA_mv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure Google Drive is mounted (it likely already is from the first question)."
      ],
      "metadata": {
        "id": "f7HeqYFKBKL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!ls \"/content/drive/MyDrive/Colab Notebooks/\""
      ],
      "metadata": {
        "id": "UgOBFJCwBPG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Install packages for converting .ipynb to .pdf"
      ],
      "metadata": {
        "id": "wDsj2M8hBOce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -q install texlive-xetex texlive-fonts-recommended texlive-plain-generic"
      ],
      "metadata": {
        "id": "0v79GdHtMy8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Convert to PDF (replace `STUDENT-ID` with your student ID)"
      ],
      "metadata": {
        "id": "_X7rUukBCKlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace STUDENT-ID with your student\n",
        "!jupyter nbconvert --to pdf \"/content/drive/MyDrive/Colab Notebooks/STUDENT-ID_Assignment_5.ipynb\""
      ],
      "metadata": {
        "id": "SwMbBqmaCH8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Download the resulting PDF file. If you are using Chrome, you can do so by running the following code. On other browsers, you can download the PDF using the file mananger on the left of the screen (Navigate to the file > Right Click > Download)."
      ],
      "metadata": {
        "id": "h4fwKz3SCSGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace STUDENT-ID with your student id below:\n",
        "from google.colab import files\n",
        "files.download(f\"/content/drive/MyDrive/Colab Notebooks/STUDENT-ID_Assignment_5.pdf\") "
      ],
      "metadata": {
        "id": "O7uiHC2uCg9-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "9cf09c8a-5e4b-4d6c-bf34-cb21c6467c7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f1a0aaf9-2742-428b-b858-76b0f1f432e8\", \"NL2DS_Winter_2023_Assignment_5_Language_Phylogeny_and_Clustering.pdf\", 64488)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Verify that your PDF correctly displays your figures and responses."
      ],
      "metadata": {
        "id": "EvvxRqqTDAFT"
      }
    }
  ]
}